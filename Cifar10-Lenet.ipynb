{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 46406,
     "status": "ok",
     "timestamp": 1530220156510,
     "user": {
      "displayName": "Thiyagarajan Ramanathan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111432628313695784552"
     },
     "user_tz": 420
    },
    "id": "uPnlO-wHN9se",
    "outputId": "100848ab-d992-42c2-8f28-e1b17898a1d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 36s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JTM7z-P9N0db"
   },
   "outputs": [],
   "source": [
    "# y_train.shape is 2d, (50000, 1). While Keras is smart enough to handle this\n",
    "# it's a good idea to flatten the array.\n",
    "y_train = y_train.reshape(-1)\n",
    "y_test = y_test.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6tb4itl4N0de"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=42, stratify = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "GNGJJhxlN0dg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "##Converting Image to grayscale\n",
    "X_train = np.sum(X_train/3, axis=3, keepdims=True)\n",
    "X_valid = np.sum(X_valid/3, axis=3, keepdims=True)\n",
    "X_test  = np.sum(X_test/3, axis=3, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cg8Y6ImhN0dj"
   },
   "outputs": [],
   "source": [
    "##Normalizing the images between 0 and 1\n",
    "X_train = (X_train - 128)/128 \n",
    "X_test= (X_test - 128)/128\n",
    "X_valid=(X_valid-128)/128\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Jpl0sJVgN0dn"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "EPOCHS = 40\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LRVw7JgKN0dq"
   },
   "outputs": [],
   "source": [
    "### Define your architecture here.\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    #Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "    conv1   = tf.nn.relu(conv1)\n",
    "\n",
    "    #Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    #Layer 2: Convolutional. Output = 10x10x16.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "    \n",
    "    #Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    x_1   = flatten(conv2) #Shape: 1600\n",
    "\n",
    "    #Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "   \n",
    "    #Layer 3: Convolutional. Output = 3x3x32.\n",
    "    conv3_W = tf.Variable(tf.truncated_normal(shape=(3, 3, 16, 32), mean = mu, stddev = sigma))\n",
    "    conv3_b = tf.Variable(tf.zeros(32))\n",
    "    conv3   = tf.nn.conv2d(conv2, conv3_W, strides=[1, 1, 1, 1], padding='VALID') + conv3_b\n",
    "    conv3   = tf.nn.relu(conv3)\n",
    "   \n",
    "    #Flatten. Input = 3x3x32. Output = 288.\n",
    "    x_2   = flatten(conv3)\n",
    "    \n",
    "    final_fc=tf.concat([x_1, x_2], 1)  #shape: 288+1600=1888\n",
    "    final_fc=tf.nn.dropout(final_fc,keep_prob)\n",
    "    # SOLUTION: Layer 3: Fully Connected. Input = 1888. Output = 1024.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(1888, 1024), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(1024))\n",
    "    fc1   = tf.matmul(final_fc, fc1_W) + fc1_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc1    = tf.nn.relu(fc1)\n",
    "\n",
    "    # SOLUTION: Layer 4: Fully Connected. Input = 1024. Output = 512.\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(1024, 512), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(512))\n",
    "    fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    \n",
    "    # SOLUTION: Activation.\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "\n",
    "    # SOLUTION: Layer 5: Fully Connected. Input = 512. Output = 10.\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(512, 10), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(10))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "scRmsB9vN0du"
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32,1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "keep_prob=tf.placeholder(tf.float32)\n",
    "one_hot_y = tf.one_hot(y,10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hjjC9upIN0dx"
   },
   "outputs": [],
   "source": [
    "rate = 0.001\n",
    "\n",
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2jJg1PIJN0d0"
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y, keep_prob:1})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2312
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 437189,
     "status": "ok",
     "timestamp": 1530221175669,
     "user": {
      "displayName": "Thiyagarajan Ramanathan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111432628313695784552"
     },
     "user_tz": 420
    },
    "id": "6NXvaVW_N0d2",
    "outputId": "072f80ab-42be-4369-9770-09ff5f100c10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.454\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.512\n",
      "\n",
      "Model saved\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.520\n",
      "\n",
      "Model saved\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.562\n",
      "\n",
      "Model saved\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.594\n",
      "\n",
      "Model saved\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.596\n",
      "\n",
      "Model saved\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.614\n",
      "\n",
      "Model saved\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.617\n",
      "\n",
      "Model saved\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.630\n",
      "\n",
      "Model saved\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.620\n",
      "\n",
      "EPOCH 11 ...\n",
      "Validation Accuracy = 0.632\n",
      "\n",
      "Model saved\n",
      "EPOCH 12 ...\n",
      "Validation Accuracy = 0.628\n",
      "\n",
      "EPOCH 13 ...\n",
      "Validation Accuracy = 0.630\n",
      "\n",
      "EPOCH 14 ...\n",
      "Validation Accuracy = 0.627\n",
      "\n",
      "EPOCH 15 ...\n",
      "Validation Accuracy = 0.627\n",
      "\n",
      "EPOCH 16 ...\n",
      "Validation Accuracy = 0.635\n",
      "\n",
      "Model saved\n",
      "EPOCH 17 ...\n",
      "Validation Accuracy = 0.621\n",
      "\n",
      "EPOCH 18 ...\n",
      "Validation Accuracy = 0.633\n",
      "\n",
      "EPOCH 19 ...\n",
      "Validation Accuracy = 0.629\n",
      "\n",
      "EPOCH 20 ...\n",
      "Validation Accuracy = 0.630\n",
      "\n",
      "EPOCH 21 ...\n",
      "Validation Accuracy = 0.634\n",
      "\n",
      "EPOCH 22 ...\n",
      "Validation Accuracy = 0.629\n",
      "\n",
      "EPOCH 23 ...\n",
      "Validation Accuracy = 0.632\n",
      "\n",
      "EPOCH 24 ...\n",
      "Validation Accuracy = 0.636\n",
      "\n",
      "Model saved\n",
      "EPOCH 25 ...\n",
      "Validation Accuracy = 0.633\n",
      "\n",
      "EPOCH 26 ...\n",
      "Validation Accuracy = 0.627\n",
      "\n",
      "EPOCH 27 ...\n",
      "Validation Accuracy = 0.633\n",
      "\n",
      "EPOCH 28 ...\n",
      "Validation Accuracy = 0.638\n",
      "\n",
      "Model saved\n",
      "EPOCH 29 ...\n",
      "Validation Accuracy = 0.618\n",
      "\n",
      "EPOCH 30 ...\n",
      "Validation Accuracy = 0.634\n",
      "\n",
      "EPOCH 31 ...\n",
      "Validation Accuracy = 0.635\n",
      "\n",
      "EPOCH 32 ...\n",
      "Validation Accuracy = 0.628\n",
      "\n",
      "EPOCH 33 ...\n",
      "Validation Accuracy = 0.638\n",
      "\n",
      "Model saved\n",
      "EPOCH 34 ...\n",
      "Validation Accuracy = 0.634\n",
      "\n",
      "EPOCH 35 ...\n",
      "Validation Accuracy = 0.631\n",
      "\n",
      "EPOCH 36 ...\n",
      "Validation Accuracy = 0.630\n",
      "\n",
      "EPOCH 37 ...\n",
      "Validation Accuracy = 0.631\n",
      "\n",
      "EPOCH 38 ...\n",
      "Validation Accuracy = 0.637\n",
      "\n",
      "EPOCH 39 ...\n",
      "Validation Accuracy = 0.633\n",
      "\n",
      "EPOCH 40 ...\n",
      "Validation Accuracy = 0.627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "with tf.Session() as sess:\n",
    "    #tf.initialize_all_variables().run()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    num_examples = len(X_train)\n",
    "    accuracy=[]\n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y,keep_prob:0.5})\n",
    "            \n",
    "        validation_accuracy = evaluate(X_valid, y_valid)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        accuracy.append(validation_accuracy)\n",
    "        if i==0:\n",
    "          continue\n",
    "        if(np.amax(accuracy)<=validation_accuracy):\n",
    "            saver.save(sess, '~/CIFAR-10 Lenet/model')\n",
    "            print(\"Model saved\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VvM6II08O4Q4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Cifar10-Lenet.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
